spring.application.name=ollama-llama-vision-llm

server.port=8095

spring.ai.ollama.base-url=http://localhost:11434/
spring.ai.ollama.chat.options.model=llama3.2-vision:11b
spring.ai.ollama.chat.options.temperature=0.8

spring.servlet.multipart.max-file-size=5MB
spring.servlet.multipart.max-request-size=5MB
